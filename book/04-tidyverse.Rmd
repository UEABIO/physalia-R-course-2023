# (PART\*) Getting the most out of tidyverse {.unnumbered}



```{r, child= '_setup.Rmd', warning = F, message = F}

```


```{r, include = FALSE}
load(here::here("book", "files", "chapter5.RData"))
library(tidyverse)
library(janitor)
```

Quick recap of the key components of the Tidyverse ecosystem.
Emphasizing the principles of tidy data and data manipulation.

# Reading files with `readr`

## Cleaning column names

Reading a CSV file often requires some data cleaning. For example, let's say I want to import data and convert all column names to `snake_case`. 

Most of us would probably read the .CSV file first, then start data cleaning - for example with the `janitor::clean_names()` function. 

```{r, eval = F}
library(tidyverse)
library(janitor)
#load data
penguins <- read_csv ("data/penguins_raw.csv")

penguins |> read_csv()
janitor::clean_names(penguins) 

```

In my previous example, I used the `clean_names()` function from the "janitor" package to convert the column names to lowercase. You can achieve the same result by using the `make_clean_names()` function within the `read_csv` function, specifying it in the `name_repair` argument.

```{r, eval = F}

penguins <- read_csv ("data/penguins_raw.csv",
                      name_repair = janitor::make_clean_names)

```

By default the `janitor::make_clean_names` function has a default argument of `snake_case` but within the function there is also a `case` argument where other common naming conventions can be used. 

## Selecting columns


In addition to cleaning your column names, you can also directly select columns while using the "read_csv" function by utilizing the "col_select" argument. This can be extremely useful when working with large files, selecting only the columns you need can be memory-efficient. 

```{r, eval = F}

penguins <- read_csv ("data/penguins_raw.csv",
                      name_repair = janitor::make_clean_names,
                      col_select = c(species, body_mass_g, flipper_length_mm)) |> 
  glimpse()

```

## Reading multiple files

```{r, eval = F}

dir.create(c("data/many_files"))
peng_samples <- map(1:25, ~ slice_sample(penguins, n = 20))

iwalk(peng_samples, ~ write_csv(., paste0("data/many_files/", .y, ".csv")))

```

### Create a vector of file paths

```{r, eval = F}

csv_files_list_files <- list.files(path = "data/many_files",
                                    pattern = "csv", full.names = TRUE)


```

```
 [1] "data/many_files/1.csv"  "data/many_files/10.csv" "data/many_files/11.csv" "data/many_files/12.csv"
 [5] "data/many_files/13.csv" "data/many_files/14.csv" "data/many_files/15.csv" "data/many_files/16.csv"
 [9] "data/many_files/17.csv" "data/many_files/18.csv" "data/many_files/19.csv" "data/many_files/2.csv" 
[13] "data/many_files/20.csv" "data/many_files/21.csv" "data/many_files/22.csv" "data/many_files/23.csv"
[17] "data/many_files/24.csv" "data/many_files/25.csv" "data/many_files/3.csv"  "data/many_files/4.csv" 
[21] "data/many_files/5.csv"  "data/many_files/6.csv"  "data/many_files/7.csv"  "data/many_files/8.csv" 
[25] "data/many_files/9.csv"
```

The function "list.files" has several arguments. Here's an explanation of some key arguments:

- "path": This argument allows you to specify the directory where your files are located. It's essential to ensure the path is set correctly. You should be working within an R-Studio project or have defined your working directory to avoid issues.

- "pattern": You provide a regular expression in this argument to filter the files you want to list. In your example, you mentioned that you are looking for files containing the string "csv." This helps narrow down the selection to specific file types or patterns.

- "full.names": Setting this argument to `TRUE` indicates that you want to store the full paths of the files, not just their names. This is important for ensuring you can correctly access and read these files later. If "full.names" is not set to `TRUE`, you may encounter difficulties when attempting to read the files because the file paths would be incomplete.

### Read multiple files

Now that we have obtained the file paths, we can proceed to load the files into R. The preferred method in the tidyverse is to use the `map_dfr` function from the `purrr` package. This function iterates through all the file paths and combines the data frames into a single, unified data frame. In the following code, `.x` represents the file name or path. To read and output the actual content of the CSV files (not just the filenames), you should include `.x` (the path) within a `readr` function. While this example deals with CSV files, this approach works similarly for other rectangular file formats.

```{r, eval = F}
df <- map_dfr(csv_files_list_files,
              ~ read_csv(.x))

glimpse(df)


```


### Selecting files

`stringr::str_detect()`

```{r, eval = F}

csv_files_list_files[str_detect(csv_files_list_files, pattern = "[2-4]",
negate = FALSE)]


```
```
 [1] "data/many_files/12.csv" "data/many_files/13.csv" "data/many_files/14.csv"
 [4] "data/many_files/2.csv"  "data/many_files/20.csv" "data/many_files/21.csv"
 [7] "data/many_files/22.csv" "data/many_files/23.csv" "data/many_files/24.csv"
[10] "data/many_files/25.csv" "data/many_files/3.csv"  "data/many_files/4.csv"
```




```{r, eval = F}

csv_files_list_files[str_detect(csv_files_list_files, pattern = "[24]\\.csv$")]

```

```
[1] "data/many_files/12.csv" "data/many_files/14.csv" "data/many_files/2.csv" 
[4] "data/many_files/22.csv" "data/many_files/24.csv" "data/many_files/4.csv"

```

# Working across columns

In this section we will go through the following functions:



- `last_col()`

- `starts_with()`

- `ends_with()`

- `contains()`

- `matches()`

- `num_range()`

- `where()`

## Select the last column

```{r}

penguins |> 
  select(last_col()) |> 
  glimpse()

```

You can also select `n-to-the-last` with `last_col()`

```{r}

penguins |> 
  select(last_col(3)) |> 
  glimpse()

```

```{block, type = "info"}

Indexing starts at 0, so 1 indicates n-1.

```


## Selecting columns based on string

```{r, eval = F}

penguins |> 
  select(starts_with("s")) |> 
  glimpse()

```
```
Rows: 344
Columns: 5
$ study_name    <chr> "PAL0708", "PAL0708", "PAL0708", "PAL0708", "PAL0708", "PAL0708", "PAL0708", "PAL0708"…
$ sample_number <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,…
$ species       <chr> "Adelie Penguin (Pygoscelis adeliae)", "Adelie Penguin (Pygoscelis adeliae)", "Adelie …
$ stage         <chr> "Adult, 1 Egg Stage", "Adult, 1 Egg Stage", "Adult, 1 Egg Stage", "Adult, 1 Egg Stage"…
$ sex           <chr> "MALE", "FEMALE", "FEMALE", NA, "FEMALE", "MALE", "FEMALE", "MALE", NA, NA, NA, NA, "F…

```

`starts_with` and `ends_with` works with any character, but also with a vector of characters

```{r, eval = F}
penguins |> 
  select(starts_with(c("s", "c"))) |> 
  glimpse()

```
```
Rows: 344
Columns: 9
$ study_name        <chr> "PAL0708", "PAL0708", "PAL0708", "PAL0708", "PAL0708", "PAL0708", "PAL0708", "PAL0…
$ sample_number     <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,…
$ species           <chr> "Adelie Penguin (Pygoscelis adeliae)", "Adelie Penguin (Pygoscelis adeliae)", "Ade…
$ stage             <chr> "Adult, 1 Egg Stage", "Adult, 1 Egg Stage", "Adult, 1 Egg Stage", "Adult, 1 Egg St…
$ sex               <chr> "MALE", "FEMALE", "FEMALE", NA, "FEMALE", "MALE", "FEMALE", "MALE", NA, NA, NA, NA…
$ clutch_completion <chr> "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "No", "No", "Yes", "Yes", "Yes", "Yes", …
$ culmen_length_mm  <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, 42.0, 37.8, 37.8, 41.1, 38.6, …
$ culmen_depth_mm   <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, 20.2, 17.1, 17.3, 17.6, 21.2, …
$ comments          <chr> "Not enough blood for isotopes.", NA, NA, "Adult not sampled.", NA, NA, "Nest neve…
```

### Contains

We can also use the `contains()` function to search for columns that contain a specific string, it searches for an exact match to your string (no regular expressions) but is case-insensitive

```{r, eval = F}
penguins |> 
  select(contains("length")) |> 
  glimpse()

```

```
Rows: 344
Columns: 2
$ culmen_length_mm  <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, 42.0, 37.8, 37.8, 41.1, 38.6, …
$ flipper_length_mm <dbl> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186, 180, 182, 191, 198, 185, 195…
```

### Regular expressions

https://help.relativity.com/RelativityOne/Content/Relativity/Regular_expressions/Searching_with_regular_expressions.htm#:~:text=For%20example%2C%20%E2%80%9C%5Cd%E2%80%9D,that%20follow%20a%20specific%20pattern.


```{r, eval = F}

penguins |> 
  select(matches("[0-9]")) |> 
  glimpse()

```
```
Rows: 344
Columns: 2
$ delta_15_n_o_oo <dbl> NA, 8.94956, 8.36821, NA, 8.76651, 8.66496, 9.18718, 9.46060, NA, 9.13362, 8.63243, …
$ delta_13_c_o_oo <dbl> NA, -24.69454, -25.33302, NA, -25.32426, -25.29805, -25.21799, -24.89958, NA, -25.09…

```

```{r, eval = F}

penguins |> 
  select(matches("[0-9]")) |> 
  glimpse()

```

```{r, eval = FALSE}
penguins |> 
    select(matches("length_[a-z][a-z]")) |> 
    glimpse()

```


## Selecting by column type

The where function is used when you want to select variables of a specific data type in a dataset. For example, you can use it to select character variables.


```{r, eval = F}

penguins |> 
    select(where(is.character)) |> 
    glimpse()

```
```
Rows: 344
Columns: 10
$ study_name        <chr> "PAL0708", "PAL0708", "PAL0708", "PAL0708", "PAL0708", "PAL0708", "PAL0708", "PAL0…
$ species           <chr> "Adelie Penguin (Pygoscelis adeliae)", "Adelie Penguin (Pygoscelis adeliae)", "Ade…
$ region            <chr> "Anvers", "Anvers", "Anvers", "Anvers", "Anvers", "Anvers", "Anvers", "Anvers", "A…
$ island            <chr> "Torgersen", "Torgersen", "Torgersen", "Torgersen", "Torgersen", "Torgersen", "Tor…
$ stage             <chr> "Adult, 1 Egg Stage", "Adult, 1 Egg Stage", "Adult, 1 Egg Stage", "Adult, 1 Egg St…
$ individual_id     <chr> "N1A1", "N1A2", "N2A1", "N2A2", "N3A1", "N3A2", "N4A1", "N4A2", "N5A1", "N5A2", "N…
$ clutch_completion <chr> "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "No", "No", "Yes", "Yes", "Yes", "Yes", …
$ date_egg          <chr> "11/11/2007", "11/11/2007", "16/11/2007", "16/11/2007", "16/11/2007", "16/11/2007"…
$ sex               <chr> "MALE", "FEMALE", "FEMALE", NA, "FEMALE", "MALE", "FEMALE", "MALE", NA, NA, NA, NA…
$ comments          <chr> "Not enough blood for isotopes.", NA, NA, "Adult not sampled.", NA, NA, "Nest neve…
```

Other "predicate functions" include

- is.double

- is.numeric

- is.logical

- is.factor

- is.integer


## Combos

Using standard logical operators such as `|` and `&` we can string toether different combinations of selection criteria

```{r, eval = FALSE}

penguins |> 
  select(where(is.numeric) | contains("species")) |> 
  glimpse()

```
```
Rows: 344
Columns: 8
$ sample_number     <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,…
$ culmen_length_mm  <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, 42.0, 37.8, 37.8, 41.1, 38.6, …
$ culmen_depth_mm   <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, 20.2, 17.1, 17.3, 17.6, 21.2, …
$ flipper_length_mm <dbl> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186, 180, 182, 191, 198, 185, 195…
$ body_mass_g       <dbl> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, 4250, 3300, 3700, 3200, 3800, …
$ delta_15_n_o_oo   <dbl> NA, 8.94956, 8.36821, NA, 8.76651, 8.66496, 9.18718, 9.46060, NA, 9.13362, 8.63243…
$ delta_13_c_o_oo   <dbl> NA, -24.69454, -25.33302, NA, -25.32426, -25.29805, -25.21799, -24.89958, NA, -25.…
$ species           <chr> "Adelie Penguin (Pygoscelis adeliae)", "Adelie Penguin (Pygoscelis adeliae)", "Ade…

```


# Modifying variables

## count

## extract

```{r, eval = F}

penguins |> 
  separate(species,
          into = c("species", "full_latin_name"),
          sep = "\\("
          )

```

This approach reaches its limits quite quickly - note here it has left an ugly `)` on the end of the second column. There are also issues when we lack a clear separator to distinguish the columns we want to create. For these use cases we have extract.

Now suppose you want to separate the common names and latin names of the species variable by regex:

```{r, eval = T}

penguins <- penguins |> 
  extract(species,
          into = c("species", "full_latin_name"),
          regex = "(\\w+) .* \\(([^)]+)\\)"
          )
penguins |> colnames()
```

- The first group captures at least 1 letter (\\w+).

- The column is then followed by a space, and all characters in between are followed by
another space: .*

- The last group contains anything found inside brackets `()`

# Factors

## Anonymising factors

Sometimes you want to make your data completely anonymous so that other people can’t see sensitive information. Or because you wish to blind you own analyses.

`forcats::fct_anon` 

```{r, eval = F}
penguins |> 
  mutate(species = fct_anon(species,
         prefix = "species_"))

```

## lump factors

```{r, eval = F}
penguins |> 
  mutate(body_size = fct_lump_min(as_factor(species), 50)) |> 
  ggplot(aes(x = body_size,
         y = flipper_length_mm))+
  geom_boxplot()

```

## ordering factors

```{r}
penguins |> 
  mutate(species = fct_relevel(species, "Adelie", "Chinstrap", "Gentoo")) |> 
  ggplot(aes(x = species))+
  geom_bar()+
  coord_flip()

```

With the function `fct_infreq` we can change the order according to how frequently each level occurs

```{r}
penguins |> 
  mutate(species = fct_infreq(species)) |> 
  ggplot(aes(x = species))+
  geom_bar()+
  coord_flip()

```


```{r}
penguins |> 
  mutate(species = fct_rev(as_factor(species))) |> 
  ggplot(aes(x = species))+
  geom_bar()+
  coord_flip()

```

`fct_reorder` allows us to order the levels based on another continuous variable

```{r, warning = FALSE}
penguins |> 
  mutate(species = as_factor(species) |> 
           fct_reorder(body_mass_g,
                       .fun = median)) |> 
  # by default the levels are ordered by the median values of the continuous variable
  # mean, min and max can all be included here
  ggplot(aes(x = species,
             y = body_mass_g,
             colour = species))+
  geom_boxplot(width = .2,
               outlier.shape = NA)+
  geom_jitter(width = .2,
              alpha = .4)
  

```


# Applying functions across columns

## calculate summary statistics across columns

```{r, eval = FALSE}
penguins |> 
  group_by(species) |> 
  summarise(
    mean_body_mass = mean(body_mass_g, na.rm = T),
    mean_flipper_length = mean(flipper_length_mm, na.rm = T)
  )

```

```{r}
penguins |> 
  group_by(species) |> 
  summarise(
    across(
      .cols = where(is.numeric),
      .fns = ~mean(.x, na.rm = T),
      .names = "mean_{.col}")
    )
  
```

## Change variable types across columns

```{r}

penguins |> 
  mutate(
    across(.cols = c("species", "island", "region"),
           .fns = as_factor)
  ) |> 
  select(where(is.factor)) |> 
  glimpse()
  

```

```
Rows: 344
Columns: 3
$ species <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…
$ region  <fct> Anvers, Anvers, Anvers, Anvers, Anvers, Anvers, Anvers, Anvers, Anvers, Anve…
$ island  <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgersen, Torgersen, Torgersen,…
```


## Correct typos

```{r}

x <- c("Adelie", "adelie", "pinstrap", "Chinstrap")
y <- c("adelie", "Adelie", "Chinstrap","Chinstrap")

typo_df <- tibble(x,y)

```


```{r}
typo_df |> 
  mutate(across(
    .cols = everything(),
    .fns = ~ case_when(
      str_detect(., "adelie") ~ str_replace(., "adelie", "Adelie"),
      str_detect(., "pinstrap") ~ str_replace(., "pinstrap", "Chinstrap"),
      TRUE ~ .
    )
  ))

```


# Working with rows

## Filtering rows based on conditions across multiple columns


```{r, eval = FALSE}

penguins |> 
  filter(
    if_any(.cols = contains("culmen"),
           .fns = ~. < 40)
  ) |> 
  glimpse()

```


```{r, eval = FALSE}

penguins |> 
  filter(
    if_all(.cols = contains("culmen"),
           .fns = ~. < 40)
  ) |> 
  glimpse()

```

## filter rows based on missing values

```{r, eval = FALSE}

penguins |> 
  filter(
    if_all(.cols = where(is.numeric),
           .fns = ~!is.na(.))
  ) 

```

```{block, type = "try"}
At first the outcome above can seem counter-intuitive, but can be explained by the `!` operator. 
The if_all is evaluating whether all columns meet the condition of NOT containing NA. 

You can try different combinations of if_all, if_any and the NOT operator

```

## slicing

```{r}
penguins |> 
  arrange(desc(body_mass_g)) |> 
  slice(1:10)

```

```{r}

penguins |> 
  arrange(desc(body_mass_g)) |> 
  rownames_to_column(var = "row_number") |> 
  slice(c(1,123,307))

```

```{r}

penguins |> 
  arrange(desc(body_mass_g)) |> 
  rownames_to_column(var = "row_number") |> 
  slice(c(-1:-340))

```

Helper functions include `slice_head()`, `slice_tail()`, `slice_max()`, `slice_min()` and `slice_sample()`
We can use these functions to more quickly and easily filter our data under some situations

```{r}
penguins |> 
  slice_max(order_by = body_mass_g,
            n = 20) |> # we can also use prop e.g. prop =.1 to slice the top 10%
  select(species, body_mass_g)

```

## groupwise slicing

```{r}
penguins |> 
  group_by(species) |> 
  slice_max(order_by = body_mass_g,
            n = 3) |> 
  select(species, body_mass_g) |> 
  ungroup()

```

## bootstrapping with slice

```{r}
set.seed(342)
bootstraps <- map(1:100, ~slice_sample(penguins, prop = .1, replace = TRUE))

bootstraps %>%
    map_dbl(~ mean(.$body_mass_g, na.rm = TRUE)) |> 
  tibble(x = _ ) |> 
ggplot(aes(x = x)) +
geom_histogram(fill = "grey80", color = "black")+
  geom_vline(data = penguins,
             aes(xintercept = mean(body_mass_g, na.rm = T)),
             linewidth = 2, colour = "red", linetype  ="dashed")


```



# Group work

The R4DS book demonstrates how functions can be used to run multiple models simultaneously. This technique is valuable for extracting meaningful insights from your data. A well-known example of this approach involves the Gapminder dataset. We will cover a brief version here: 

To find out how well culmen length can predict culmen depth we build a linear regression model.

Once we have created the model, we can retrieve the results parameters and test statistics
with the summary function:
`summary(model)`

```{r}

model <- lm(culmen_depth_mm ~ culmen_length_mm, data = penguins)

summary(model)

```

Now we know that there are important covariates to consider - and the most appropriate method from an analysis perspective would be to include these as covariates within a single model

```{r, eval = F}
model <- lm(culmen_depth_mm ~ culmen_length_mm * species, data = penguins)

summary(model)

```

```
Call:
lm(formula = culmen_depth_mm ~ culmen_length_mm * species, data = penguins)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.6574 -0.6675 -0.0524  0.5383  3.5032 

Coefficients:
                                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)                       11.40912    1.13812  10.025  < 2e-16 ***
culmen_length_mm                   0.17883    0.02927   6.110 2.76e-09 ***
speciesChinstrap                  -3.83998    2.05398  -1.870 0.062419 .  
speciesGentoo                     -6.15812    1.75451  -3.510 0.000509 ***
culmen_length_mm:speciesChinstrap  0.04338    0.04558   0.952 0.341895    
culmen_length_mm:speciesGentoo     0.02601    0.04054   0.642 0.521590    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9548 on 336 degrees of freedom
  (2 observations deleted due to missingness)
Multiple R-squared:  0.7697,	Adjusted R-squared:  0.7662 
F-statistic: 224.5 on 5 and 336 DF,  p-value: < 2.2e-16

```

However, there may be occasions where we wish to apply simple models to each subpopulation in turn:

```{r, eval = F}
penguins |> 
  group_by(species) |> 
  nest() |> 
  mutate(model = map(data, ~ lm(culmen_depth_mm ~ culmen_length_mm, data = .))) |> 
  mutate(tidy = map(model, broom::tidy)) |> 
  unnest(tidy)

```
```
A tibble:6 × 8
Groups:species [3]

Adelie	<tibble>	<S3: lm>	(Intercept)	11.4091245	1.33893250	
Adelie	<tibble>	<S3: lm>	culmen_length_mm	0.1788343	0.03443569	
Gentoo	<tibble>	<S3: lm>	(Intercept)	5.2510084	1.05480901	
Gentoo	<tibble>	<S3: lm>	culmen_length_mm	0.2048443	0.02215802	
Chinstrap	<tibble>	<S3: lm>	(Intercept)	7.5691401	1.55052928	
Chinstrap	<tibble>	<S3: lm>	culmen_length_mm	0.2222117	0.03167825	
6 rows | 1-6 of 8 columns

```

# Pivot

## pivot wider

```{block, type = "info"}

Un-tidy data violates one of these three principles in one way or another:

• Each variable forms a column
• Each observation forms a row
• Each type of observation unit is a table

```


```{r}

wk1 <- c(1,2,4,5)
wk2 <- c(3,4,1,0)
wk3 <- c(0,0,2,0)
penguin_id <- c("N15A1" , "N15A2" , "N18A1", "N71A2")

peng_obs <- tibble(penguin_id, wk1,wk2,wk3)
```

This data is untidy because a value that measures the same underlying attribute (number of observations) is split across three columns. Here wk1,wk2 and wk3 represent the underlying variable of observations split across three weeks.

We can use pivot to create a tidy representation of the data

```{r}
peng_obs |> 
  pivot_longer(
    cols = "wk1":"wk3",
    names_to = "week",
    values_to = "observations"
  )

```

We can tidy this dataframe further by removing the "wk" prefix:

```{r}
peng_obs |> 
  pivot_longer(
    cols = "wk1":"wk3",
    names_to = "week",
    names_prefix = "wk",
    values_to = "observations"
  )

```
```{block, type = "warning"}

Note that the week column is still being treated as a character string. using `names_transform` we can fix this

```

```{r}
peng_obs |> 
  pivot_longer(
    cols = "wk1":"wk3",
    names_to = "week",
    names_prefix = "wk",
    names_transform = as.integer,
    values_to = "observations"
  )

```

## pivot longer

Suppose you would like to make a data frame wider because you would like to present the results in a human-readable table. To do this, you can use pivot_wider and provide arguments for its main parameters:

- id_cols: These columns are the identifiers for the observations. These column names
remain unchanged in the data frame. Their values form the rows of the transformed data
frame. By default, all columns except those specified in names_from and values_from
become id_cols.

-  names_from: These columns will be transformed into a wider format. Their values will
be converted to columns. If you specify more than one column for names_from, the
newly created column names will be a combination of the column values.

- values_from: The values of these columns will be used for the columns created with
names_from.


## pivot wider for summary tables

```{r}

penguins |> 
  group_by(species, island) |> 
  summarise(mean = mean(body_mass_g, na.rm = T))

```



```{r}
penguins |> 
  group_by(species, island) |> 
  summarise(mean = mean(body_mass_g, na.rm = T)) |> 
  pivot_wider(names_from = c(species, island),
              values_from = mean,
              names_prefix = "mean_")

```

# Writing Functions in Tidyverse

The goal here is to understand how to use tidy evaluation to write functions that incorporate `{tidyverse}` functions e.g. (mutate, select, filter) etc. 

Below is an example of some code to select a variable:

```{r}
penguins |> 
  select(species)

```

Put that exact working code into a function

```{r, eval = F}

test_function <- function(select_var){
  penguins |> 
  select(select_var)
}

test_function(select_var = species)

```
```
Error: object 'species' not found

```

This error occurs becaus of *tidy evaluation*

```{block, type = "info"}

Tidy evaluation: A framework for controlling how expressions and variables in your code are evaluated by tidyverse functions.

- Allows programmers to select variables based on their position, name, or type

- Useful for passing variable names as inputs to functions that use tidyverse packages like dplyr and ggplot2

- {dplyr} verbs rely on tidy evaluation to resolve programming commands

```

## Data masking

Data masking is a handy feature of tidyverse that makes it easier to program with dataframes. It allows you to reference columns wihout using `$`, whereas almost all base R functions use unmasked programming.

However, this makes it harder to create functions

Data masking is used by `arrange()`, `count()`, `filter()`, `group_by()`, `mutate()`, and `summarise()`. To check which type of tidy evaluation a function uses, check the help file. 

```{r}

test_filter_species <- function(filter_var) {
  penguins %>%
    filter(species == filter_var)
}

test_filter_species("Adelie") %>%
  glimpse()

```

By passing quoted arguments to the function, you can use it directly in the expression, and the function will evaluate it as if it were part of the data frame. 

```{r, eval = F}
test_filter_general <- function(filter_condition) {
  penguins %>%
    filter(filter_condition)
}

test_filter_general("flipper_length_mm > 180") %>%
  glimpse()

```

```
Error in `filter()`:
ℹ In argument: `filter_condition`.
Caused by error:
! `..1` must be a logical vector, not the string "fliper_length_mm > 180".
Backtrace:
  1. test_filter_general("flipper_length_mm > 180") %>% glimpse()
 12. dplyr:::dplyr_internal_error(...)

```

However, we can avoid this by embracing the curly operators `{{.}}` this allows the data-masked argument to have its evaluation delayed until after the data frame columns are defined. With the `{{` operator you can tunnel data-variables (i.e. columns from the data frames) through arg-variables (function arguments). 

```{r, eval = T}
test_filter_general <- function(filter_condition) {
  penguins %>%
    filter({{filter_condition}})
}

test_filter_general(flipper_length_mm > 180) %>%
  glimpse()

```

Let's try another data-masked function

```{r}

summary_table <- function(df, var){
  df |> 
    summarise(mean = mean({{var}}, na.rm = T),
              sd = sd({{var}}, na.rm = T))
}

summary_table(penguins, body_mass_g)


```

### Alternative to `{{}}`

The `{{.}}` is a shortcut for `!!enquo(.)` Where `rlang::enquo()` captures and quote an argument or an expression. The result of `enquo()` is a **quosure**, which is a combination of the quoted expression and its associated environment. 

`!!` This is the unquote operator. It's used to unquote or unsplice the contents of a quosure. In other words, it takes the quoted expression out of the quosure and evaluates it. We can see how this would work for one of our previous examples: 

```{r}
test_filter_general <- function(filter_condition) {
  
  filter_quo <- enquo(filter_condition)
  
  penguins %>%
    filter(!!filter_quo)
}

test_filter_general(flipper_length_mm > 180) %>%
  glimpse()

```

## tidy-select

When using functions that use tidy-select, we put variable names in quotes and use th `all_of` and `any_of` functions.

```{r, eval = F}
my_select_function <- function(select_variable){
  penguins |> 
    dplyr::select(select_variable)
  }

my_select_function(species) |> 
  glimpse()
```

```
Error: object 'species' not found

```

```{r, eval = F}
my_select_function <- function(select_variable){
  penguins |> 
    dplyr::select(select_variable)
  }

my_select_function("species") |> 
  glimpse()
```

```
Warning: Using an external vector in selections was deprecated in tidyselect 1.1.0.
Please use `all_of()` or `any_of()` instead.
# Was:
data %>% select(select_variable)

# Now:
data %>% select(all_of(select_variable))

```

- `any_of()`: selecting any of the listed variables

- `all_of()`: for strict selection. If any of the variables in the character vector is missing, an error is thrown

- Can also use `!all_of()` to select all variables not found in the character vector supplied to all_of()


```{r}

my_select_function <- function(select_variable){
  penguins |> 
    dplyr::select(dplyr::all_of(select_variable))
  }

my_select_function(select_variable = c("species", "sex")) |> 
  glimpse()

```
## Practice

```{task}

Write a `function` that uses filter to take any two of the penguin species then selects one numeric variable e.g. body_mass_g and compares them with a violin plot (`geom_violin()`)


```


```{solution}

``{r}
compare_species_plot <- function(data, species_1, species_2, feature) {
    
  filtered_data <- data |> 
        filter(species %in% c(species_1, species_2))
    
    # Create a conditional ggplot
    ggplot(filtered_data, aes(x = species, y = {{feature}}))+ 
      geom_violin()
        

}

compare_species_plot(penguins, "Adelie", "Chinstrap", culmen_length_mm)

``

```

In the example below I have used `enquo` to enable conversion to character strings, this means all of the function arguments can be provided without "quotes". 

```{solution}

``{r, eval = F, warning = "FALSE"}

compare_species_plot <- function(data, species_1, species_2, feature) {
    
   
    
    # Quote species_1 and species_2 using quosures
    species_1_quo <- quo_name(enquo(species_1))
    species_2_quo <- quo_name(enquo(species_2))
    

    filtered_data <- data |> 
        filter(species %in% c(species_1_quo, species_2_quo))
    
    # Create a conditional ggplot
    ggplot(filtered_data, aes(x = species, y = {{feature}})) +
        geom_violin()
}

# Example usage without quotes for species names

compare_species_plot(penguins, Adelie, Chinstrap, culmen_length_mm)

``

```


## Practice

Can you write your own custom function in tidyverse? 
