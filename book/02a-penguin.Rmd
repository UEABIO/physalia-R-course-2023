# Penguin project

```{r, child='_setup.Rmd'}

```

In this workshop we will work through setting up a project and loading data. Once we have a curated and cleaned the dataset we can work on generating insights from the data.

As a biologist you should be used to asking questions and gathering data. It is also important that you learn all aspects of the research process. This includes responsible data management (understanding data files & spreadsheet organisation, keeping data safe) and data analysis.

In this chapter we will look at the structure of data files, and how to read these with R. We will also continue to develop reproducible scripts. This means that we are writing scripts that are well organised and easy to read, and also making sure that our scripts are complete and capable of reproducing an analysis from start to finish. 

Transparency and reproducibility are key values in scientific research, when you analyse data in a reproducible way it means that others can understand and check your work. It also means that the most important person can benefit from your work, YOU! When you return to an analysis after even a short break, you will be thanking your earlier self if you have worked in a clear and reproducible way, as you can pick up right where you left off.  


## Meet the Penguins

This data, taken from the `palmerpenguins` (@R-palmerpenguins) package was originally published by @Antarctic. In our course we will work with real data that has been shared by other researchers.

The palmer penguins data contains size measurements, clutch observations, and blood isotope ratios for three penguin species observed on three islands in the Palmer Archipelago, Antarctica over a study period of three years.

```{r, eval=TRUE, echo=FALSE, out.width="80%", fig.alt= "Photo of three penguin species, Chinstrap, Gentoo, Adelie"}
knitr::include_graphics("images/gorman-penguins.jpg")
```

These data were collected from 2007 - 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data were imported directly from the Environmental Data Initiative (EDI) Data Portal, and are available for use by CC0 license (‚ÄúNo Rights Reserved‚Äù) in accordance with the Palmer Station Data Policy. We gratefully acknowledge Palmer Station LTER and the US LTER Network. Special thanks to Marty Downs (Director, LTER Network Office) for help regarding the data license & use. Here is our intrepid package co-author, Dr. Gorman, in action collecting some penguin data:

```{r, eval=TRUE, echo=FALSE, out.width="80%", fig.alt= "Photo of Dr Gorman in the middle of a flock of penguins"}
knitr::include_graphics("images/penguin-expedition.jpg")
```

Here is a map of the study site

```{r, eval=TRUE, echo=FALSE, out.width="80%", fig.alt= "Antarctic Peninsula and the Palmer Field Station"}
knitr::include_graphics("images/antarctica-map.png")
```

## Activity 1: Organising our workspace

Before we can begin working with the data, we need to do some set-up. 

* Go to RStudio Cloud and open the `Penguins` R project

* Create the following folders using the + New Folder button in the Files tab

  * data
  * outputs
  * scripts
  

```{block, type = "warning"}
R is case-sensitive so type everything EXACTLY as printed here
```


```{r, eval = F}

dir.create("data",
           showWarnings = FALSE)

dir.create("outputs",
           showWarnings = FALSE)

dir.create("scripts",
           showWarnings = FALSE)

# or this can be run using apply
lapply(c("data", "outputs", "scripts"), function(dir_name) {
  dir.create(dir_name, showWarnings = FALSE)
})


```

Having these separate subfolders within our project helps keep things tidy, means it's harder to lose things, and lets you easily tell R exactly where to go to retrieve data.  

The next step of our workflow is to have a well organised project space. RStudio Cloud does a lot of the hard work for you, each new data project can be set up with its own Project space. 

We will define a project as a series of linked questions that uses one (or sometimes several) datasets. For example a coursework assignment for a particular module would be its own project, a series of linked experiments or particular research project might be its own project.

A Project will contain several files, possibly organised into sub-folders containing data, R scripts and final outputs. You might want to keep any information (wider reading) you have gathered that is relevant to your project.

```{r, eval=TRUE, echo=FALSE, out.width="80%", fig.cap = "An example of a typical R project set-up"}
knitr::include_graphics("images/project.png")
```

Within this project you will notice there is already one file *.Rproj*. This is an R project file, this is a very useful feature, it interacts with R to tell it you are working in a very specific place on the computer (in this case the cloud server we have dialed into). It means R will automatically treat the location of your project file as the 'working directory' and makes importing and exporting easier^[More on projects can be found in the R4DS book (https://r4ds.had.co.nz/workflow-projects.html)]. 

```{block, type = "warning"}
It is very important to NEVER to move the .Rproj file, this may prevent your workspace from opening properly. 
```

## Activity 2: Access our data

Now that we have a project workspace, we are ready to import some data.

* Use the link below to open a page in your browser with the data open

* Right-click Save As to download in csv format to your computer (Make a note of **where** the file is being downloaded to e.g. Downloads)


```{r, eval = TRUE, echo = FALSE}
downloadthis::download_link(
  link = "https://raw.githubusercontent.com/UEABIO/data-sci-v1/main/book/files/penguins_raw.csv",
  button_label = "Download penguin data as csv",
  button_type = "success",
  has_icon = TRUE,
  icon = "fa fa-save",
  self_contained = FALSE
)
```



```{r, eval=TRUE, echo=FALSE, out.width="80%", fig.alt= "excel view, csv view", fig.cap = "Top image: Penguins data viewed in Excel, Bottom image: Penguins data in native csv format"}
knitr::include_graphics("images/excel_csv.png")
```

In raw format, each line of a CSV is separated by commas for different values. When you open this in a spreadsheet program like Excel it automatically converts those comma-separated values into tables and columns. 


## Activity 3: Upload our data

* The data is now in your Downloads folder on your computer

* We need to upload the data to our remote cloud-server (RStudio Cloud), select the upload files to server button in the Files tab

* Put your file into the data folder - if you make a mistake select the tickbox for your file, go to the cogs button and choose the option Move.

```{r, eval=TRUE, echo=FALSE, out.width="80%", fig.alt= "File tab", fig.cap = "Highlighted the buttons to upload files, and more options"}
knitr::include_graphics("images/upload.png")
```


### Read data from a url

It is also possible to use a url as a filepath

```{r, eval = F}

read_csv("https://raw.githubusercontent.com/UEABIO/data-sci-v1/main/book/files/penguins_raw.csv")

```

## Activity 4: Make a script

Let's now create a new R script file in which we will write instructions and store comments for manipulating data, developing tables and figures. Use the `File > New Script` menu item and select an R Script. 

Add the following:

```{r}
#___________________________----
# SET UP ----
## An analysis of the bill dimensions of male and female Adelie, Gentoo and Chinstrap penguins ----

### Data first published in  Gorman, KB, TD Williams, and WR Fraser. 2014. ‚ÄúEcological Sexual Dimorphism and Environmental Variability Within a Community of Antarctic Penguins (Genus Pygoscelis).‚Äù PLos One 9 (3): e90081. https://doi.org/10.1371/journal.pone.0090081. ----
#__________________________----

```

Then load the following add-on package to the R script, just underneath these comments. Tidyverse isn't actually one package, but a bundle of many different packages that play well together - for example it *includes* `ggplot2` which we used in the last session, so we don't have to call that separately

Add the following to your script:

```{r, eval = F}
# PACKAGES ----
library(tidyverse) # tidy data packages
library(janitor) # cleans variable names
#__________________________----
```

Save this file inside the scripts folder and call it `01_import_penguins_data.R`

```{block, type = "try"}
Click on the document outline button (top right of script pane). This will show you how the use of the visual outline

Allows us to build a series of headers and subheaders, this is very useful when using longer scripts.

```

## Activity 5: Read in data

Now we can read in the data. To do this we will use the function `readr::read_csv()` that allows us to read in .csv files. There are also functions that allow you to read in .xlsx files and other formats, however in this course we will only use .csv files.

* First, we will create an object called `penguins_data` that contains the data in the `penguins_raw.csv` file. 

* Add the following to your script, and check the document outline:


```{multCode}

``{r, eval = F}
penguins_raw <- read.csv("data/penguins_raw.csv")

# penguins_raw <- read.csv(here("data", "penguins_raw.csv"))

attributes(penguins_raw) # reads as data.frame

head(penguins_raw) # check the data has loaded, prints first 10 rows of dataframe

``

####

``{r, eval = F}
# IMPORT DATA ----
penguins_raw <- read_csv ("data/penguins_raw.csv")

# penguins_raw <- read_csv(here("data", "penguins_raw.csv"))

attributes(penguins_raw) # reads as tibble

head(penguins_raw) # check the data has loaded, prints first 10 rows of dataframe
#__________________________----
``

```


```{block, type = "danger"}
Note the differences between `read.csv()` and `read_csv`. We covered this in differences between tibbles and dataframes - here most obviously is a difference in column names. 
```


## Activity: Check your script

`r hide("Solution")`

```{r, eval = F}

#___________________________----
# SET UP ----
## An analysis of the bill dimensions of male and female Adelie, Gentoo and Chinstrap penguins ----

### Data first published in  Gorman, KB, TD Williams, and WR Fraser. 2014. ‚ÄúEcological Sexual Dimorphism and Environmental Variability Within a Community of Antarctic Penguins (Genus Pygoscelis).‚Äù PLos One 9 (3): e90081. https://doi.org/10.1371/journal.pone.0090081. ----
#__________________________----

# PACKAGES ----
library(tidyverse) # tidy data packages
library(janitor) # cleans variable names
library(lubridate) # make sure dates are processed properly
#__________________________----

# IMPORT DATA ----
penguins_raw <- read_csv ("data/penguins_raw.csv")

head(penguins_raw) # check the data has loaded, prints first 10 rows of dataframe
#__________________________----

```

`r unhide()`

## Activity: Test yourself

**Question 1.** In order to make your R project reproducible what filepath should you use? 

`r mcq(c("Absolute filepath", answer = "Relative filepath"))`

**Question 2.** Which of these would be acceptable to include in a raw datafile? 

`r mcq(c("Highlighting some blocks of cells", "Excel formulae", answer = "A column of observational notes from the field", "a mix of ddmmyy and yymmdd date formats"))`

**Question 3.** What should always be the first set of functions in our script? `?()`

`r fitb("library()")`

**Question 4.** When reading in data to R we should use

`r mcq(c(answer = "read_csv()", "read.csv()"))`

**Question 5.** What format is the `penguins_raw` data in?

`r mcq(c("wide data", answer = "long data"))`

`r hide("Explain This Answer")`
```{r, echo = FALSE, results='asis'}
cat("Each column is a unique variable and each row is a unique observation so this data is in a long (tidy) format")
```
`r unhide()`  

**Question 6.** The working directory for your projects is by default set to the location of?

`r mcq(c("your data files", answer = "the .Rproj file", "your R script"))`

**Question 7.** Using the filepath `"data/penguins_raw.csv"` is an example of 

`r mcq(c("an absolute filepath", answer = "a relative filepath"))`

**Question 8.** What operator do I need to use if I wish to assign the output of the `read_csv` function to an R object (rather than just print the dataframe into the console)?

`r fitb("<-")`

# Data wrangling with dplyr

```{r, child='_setup.Rmd'}

```


```{r, echo = F, warning = F, message = F}
library(tidyverse)
library(janitor)
library(here)

penguins_raw <- read_csv(here("book", "files", "penguins_raw.csv"))
```

In this chapter you will learn how to use tidyverse functions to data clean and wrangle: 

## Activity 1: Change column names

We are going to learn how to organise data using the *tidy* format^[(http://vita.had.co.nz/papers/tidy-data.pdf)]. This is because we are using the `tidyverse` packages @R-tidyverse. This is an opinionated, but highly effective method for generating reproducible analyses with a wide-range of data manipulation tools. Tidy data is an easy format for computers to read. It is also the required data structure for our **statistical tests** that we will work with later.

Here 'tidy' refers to a specific structure that lets us manipulate and visualise data with ease. In a tidy dataset each *variable* is in one column and each row contains one *observation*. Each cell of the table/spreadsheet contains the *values*. One observation you might make about tidy data is it is quite long - it generates a lot of rows of data - you might remember then that *tidy* data can be referred to as *long*-format data (as opposed to *wide* data). 

```{r, eval=TRUE, echo=FALSE, out.width="80%", fig.alt= "tidy data overview"}
knitr::include_graphics("images/tidy-1.png")
```

So we know our data is in R, and we know the columns and names have been imported. But we still don't know whether all of our values imported correctly, or whether it captured all the rows. 

#### Add this to your script 

```{r, eval = F}
# CHECK DATA----
# check the data
colnames(penguins_raw)
#__________________________----
```

When we run `colnames()` we get the identities of each column in our dataframe

* **Study name**: an identifier for the year in which sets of observations were made

* **Region**: the area in which the observation was recorded

* **Island**: the specific island where the observation was recorded

* **Stage**: Denotes reproductive stage of the penguin

* **Individual** ID: the unique ID of the individual

* **Clutch completion**: if the study nest observed with a full clutch e.g. 2 eggs

* **Date egg**: the date at which the study nest observed with 1 egg

* **Culmen length**: length of the dorsal ridge of the bird's bill (mm)

* **Culmen depth**: depth of the dorsal ridge of the bird's bill (mm)

* **Flipper Length**: length of bird's flipper (mm)

* **Body Mass**: Bird's mass in (g)

* **Sex**: Denotes the sex of the bird

* **Delta 15N** : the ratio of stable Nitrogen isotopes 15N:14N from blood sample

* **Delta 13C**: the ratio of stable Carbon isotopes 13C:12C from blood sample


#### Clean column names

Often we might want to change the names of our variables. They might be non-intuitive, or too long. Our data has a couple of issues:

* Some of the names contain spaces

* Some of the names have capitalised letters

* Some of the names contain brackets

This dataframe  does not like these so let's correct these quickly. R is case-sensitive and also doesn't like spaces or brackets in variable names

```{r, eval = T, warning = F, message = F}
# CLEAN DATA ----

# clean all variable names to snake_case using the clean_names function from the janitor package
# note we are using assign <- to overwrite the old version of penguins with a version that has updated names
# this changes the data in our R workspace but NOT the original csv file

penguins_clean <- janitor::clean_names(penguins_raw) # clean the column names

colnames(penguins_clean) # quickly check the new variable names


```

#### Rename columns (manually)

The `clean_names` function quickly converts all variable names into snake case. The N and C blood isotope ratio names are still quite long though, so let's clean those with `dplyr::rename()` where "new_name" = "old_name".

```{multCode}

``{r, eval= FALSE}

names(penguins)[names(penguins_clean) == "delta_15_n_o_oo"] <- "delta_15n"

names(penguins)[names(penguins_clean) == "delta_13_c_o_oo"] <- "delta_13c"
``

####

``{r, eval = T, warning = F, message = F}
# shorten the variable names for N and C isotope blood samples

penguins <- rename(penguins_clean,
         "delta_15n"="delta_15_n_o_oo",  # use rename from the dplyr package
         "delta_13c"="delta_13_c_o_oo")

``

```

## Check data

#### glimpse: check data format 

When we run `glimpse()` we get several lines of output. The number of observations "rows", the number of variables "columns". Check this against the csv file you have - they should be the same. In the next lines we see variable names and the type of data. 


```{multCode}


``{r, eval = F}

attributes(penguins)

``

####

``{r, eval = F}
glimpse(penguins)
``

```

We can see a dataset with 345 rows (including the headers) and 17 variables
It also provides information on the *type* of data in each column

* `<chr>` - means character or text data

* `<dbl>` - means numerical data

#### Rename text values

Sometimes we may want to rename the values in our variables in order to make a shorthand that is easier to follow. This is changing the **values** in our columns, not the column names. 


```{multCode}

``{r, eval = F, warning = F, message = F}

penguins$species <- ifelse(penguins$species == "Adelie Penguin (Pygoscelis adeliae)", "Adelie",
                          ifelse(penguins$species == "Gentoo penguin (Pygoscelis papua)", "Gentoo",
                                 ifelse(penguins$species == "Chinstrap penguin (Pygoscelis antarctica)", "Chinstrap",
                                        penguins$species)))


``

####

``{r, eval = T, warning = F, message = F}
# use mutate and case_when for a statement that conditionally changes the names of the values in a variable
penguins <- penguins |> 
  mutate(species = case_when(species == "Adelie Penguin (Pygoscelis adeliae)" ~ "Adelie",
                             species == "Gentoo penguin (Pygoscelis papua)" ~ "Gentoo",
                             species == "Chinstrap penguin (Pygoscelis antarctica)" ~ "Chinstrap"))

``

```



```{block, type = "warning"}

Have you checked that the above code block worked? Inspect your new tibble and check the variables have been renamed as you wanted.

```


## dplyr verbs

In this section we will be introduced to some of the most commonly used data wrangling functions, these come from the `dplyr` package (part of the `tidyverse`). These are functions you are likely to become *very* familiar with. 

```{r, eval = TRUE, echo = FALSE, warning = FALSE, message = FALSE}
library(kableExtra)

verb <- c( "select()","filter()", "arrange()", "summarise()", "group_by()", "mutate()")

action <- c("take a subset of columns","take a subset of rows",  "reorder the rows", "reduce raw data to user defined summaries", "group the rows by a specified column", "create a new variable")

box <- tibble(verb, action)
box
# box |> 
#   kbl(caption = "dplyr verbs", 
#    booktabs = T) |> 
#   kable_styling(full_width = FALSE, font_size=16)

```

### Select

If we wanted to create a dataset that only includes certain variables, we can use the `select()` function from the `dplyr` package. 

For example I might wish to create a simplified dataset that only contains `species`, `sex`, `flipper_length_mm` and `body_mass_g`. 

Run the below code to select only those columns

```{multCode}

``{r, eval= F}
penguins[c("species", "sex", "flipper_length_mm", "body_mass_g")]
``

####

``{r, eval = F}

# DPLYR VERBS ----

select(.data = penguins, # the data object
       species, sex, flipper_length_mm, body_mass_g) # the variables you want to select
``

```

Alternatively you could tell R the columns you **don't** want e.g. 

```{multCode}

``{r, eval = F}
penguins[, !colnames(penguins) %in% c("study_name", "sample_number")]
``

####

``{r, eval = F}
select(.data = penguins,
       -study_name, -sample_number)

``

```

Note that `select()` does **not** change the original `penguins` tibble. It spits out the new tibble directly into your console. 

If you don't **save** this new tibble, it won't be stored. If you want to keep it, then you must create a new object. 

When you run this new code, you will not see anything in your console, but you will see a new object appear in your Environment pane.

```{r, eval = F}
new_penguins <- select(.data = penguins, 
       species, sex, flipper_length_mm, body_mass_g)
```

### Filter

Having previously used `select()` to select certain variables, we will now use `filter()` to select only certain rows or observations. For example only Adelie penguins. 

We can do this with the equivalence operator `==`

```{multCode}

``{r, eval = F}

filtered_penguins <- new_penguins[new_penguins$species == "Adelie Penguin (Pygoscelis adeliae"), ]

``

####

``{r, eval = F}
filter(.data = new_penguins, species == "Adelie Penguin (Pygoscelis adeliae)")

``

```

We can use several different operators to assess the way in which we should filter our data that work the same in tidyverse or base R.

```{r, eval = TRUE, echo = FALSE, warning = FALSE, message = FALSE}

Operator <- c("A < B", "A <= B", "A > B", "A >= B", "A == B", "A != B", "A %in% B")

Name <- c("less than", "less than or equal to", "greater than", "greater than or equal to", "equivalence", "not equal", "in")

box <- tibble(Operator, Name)

box |> 
   kbl(caption = "Boolean expressions", 
    booktabs = T) |> 
   kable_styling(full_width = FALSE, font_size=16)

```

If you wanted to select all the Penguin species except Adelies, you use 'not equals'.

```{r, eval = F}
filter(.data = new_penguins, species != "Adelie")

```

This is the same as 

```{r, eval = F}
filter(.data = new_penguins, species %in% c("Chinstrap", "Gentoo"))
```

You can include multiple expressions within `filter()` and it will pull out only those rows that evaluate to `TRUE` for all of your conditions. 

For example the below code will pull out only those observations of Adelie penguins where flipper length was measured as greater than 190mm. 

```{multCode}

``{r, eval =F}
new_penguins[new_penguins$species == "Adelie" & new_penguins$flipper_length_mm > 190, ]
``

####

``{r, eval =F}

filter(.data = new_penguins, species == "Adelie", flipper_length_mm > 190)

``

```

### Arrange

The function `arrange()` sorts the rows in the table according to the columns supplied. For example

```{multCode}

``{r, eval = F}
new_penguins[order(new_penguins$sex), ] # define columns to be arranged
``

####

``{r, eval = F}
arrange(.data = new_penguins, sex)
``

```

The data is now arranged in alphabetical order by sex. So all of the observations of female penguins are listed before males. 

You can also reverse this with `desc()`

```{r, eval = F}

arrange(.data = new_penguins, desc(sex))

```

You can also sort by more than one column, what do you think the code below does?

```{r, eval = F}
arrange(.data = new_penguins,
        sex,
        desc(species),
        desc(flipper_length_mm))
```

### Mutate

Sometimes we need to create a new variable that doesn't exist in our dataset. For example we might want to figure out what the flipper length is when factoring in body mass. 

To create new variables we use the function `mutate()`. 

Note that as before, if you want to save your new column you must save it as an object. Here we are mutating a new column and attaching it to the `new_penguins` data oject.

```{multCode}

``{r, eval = F}

new_penguins$body_mass_kg <- new_penguins$body_mass_g / 1000

``

####

``{r, eval = F}
new_penguins <- mutate(.data = new_penguins,
                     body_mass_kg = body_mass_g/1000)
``

```

## Pipes

```{r, eval=TRUE, echo=FALSE, out.width="80%", fig.alt= "Pipes make code more human readable"}
knitr::include_graphics("images/pipe_order.jpg")
```

Pipes look like this: `|>` Pipes allow you to send the output from one function straight into another function. Specifically, they send the result of the function before `|>` to be the **first** argument of the function after `|>`. As usual, it's easier to show, rather than tell so let's look at an example.

```{r, eval = F}
# this example uses brackets to nest and order functions
arrange(.data = filter(.data = select(.data = penguins, species, sex, flipper_length_mm), sex == "MALE"), desc(flipper_length_mm))

```

```{r, eval = F}
# this example uses sequential R objects to make the code more readable
object_1 <- select(.data = penguins, species, sex, flipper_length_mm)
object_2 <- filter(.data = object_1, sex == "MALE")
arrange(object_2, desc(flipper_length_mm))

```

```{r, eval = F}
# this example is human readable without intermediate objects
penguins |>  
  select(species, sex, flipper_length_mm) |>  
  filter(sex == "MALE") |>  
  arrange(desc(flipper_length_mm))
```

The reason that this function is called a pipe is because it 'pipes' the data through to the next function. When you wrote the code previously, the first argument of each function was the dataset you wanted to work on. When you use pipes it will automatically take the data from the previous line of code so you don't need to specify it again.

```{task}
Try and write out as plain English what the |>  above is doing? You can read the |>  as THEN
```

`r hide("Solution")`

Take the penguins data AND THEN
Select only the species, sex and flipper length columns AND THEN
Filter to keep only those observations labelled as sex equals male AND THEN
Arrange the data from HIGHEST to LOWEST flipper lengths.

`r unhide()`

```{block, type = "info"}

From R version 4 onwards there is now a "native pipe" `|>`

This doesn't require the tidyverse `magrittr` package and the "old pipe" `%>%` or any other packages to load and use. 

You may be familiar with the magrittr pipe or see it in other tutorials, and website usages. The native pipe works equivalntly in most situations but if you want to read about some of the operational differences, [this site](https://www.infoworld.com/article/3621369/use-the-new-r-pipe-built-into-r-41.html) does a good job of explaining .


```


## A few more handy functions

### Check for duplication

It is very easy when inputting data to make mistakes, copy something in twice for example, or if someone did a lot of copy-pasting to assemble a spreadsheet (yikes!). We can check this pretty quickly

```{r, eval = F}
# check for duplicate rows in the data
penguins |> 
  duplicated() |>  # produces a list of TRUE/FALSE statements for duplicated or not
  sum() # sums all the TRUE statements

```

```
[1] 0
```
Great! 

If I did have duplications I could investigate further

```{r, eval = F}

# Check duplicated rows
penguins |> 
    filter(duplicated(penguins))

```


```{r, eval = F}

# Keep only unduplicated data
penguins |> 
    filter(!duplicated(penguins))

```

### Summarise

We can also  explore our data for very obvious typos by checking for implausibly small or large values, this is a simple use of the `summarise` function.

```{r, eval = F}
# use summarise to make calculations
penguins |> 
  summarise(min=min(body_mass_g, na.rm=TRUE), 
            max=max(body_mass_g, na.rm=TRUE))

```

The minimum weight for our penguins is 2.7kg, and the max is 6.3kg - not outrageous. If the min had come out at 27g we might have been suspicious. We will use `summarise` again to calculate other metrics in the future. 

```{block, type = "info"} 
Our first data insight, the difference the smallest adult penguin in our dataset is nearly half the size of the largest penguin. 
```

### Group By

Many data analysis tasks can be approached using the ‚Äúsplit-apply-combine‚Äù paradigm: split the data into groups, apply some analysis to each group, and then combine the results. `dplyr` makes this very easy with the `group_by()` function. In the `summarise` example above we were able to find the max-min body mass values for the penguins in our dataset. But what if we wanted to break that down by a grouping such as species of penguin. This is where `group_by()` comes in.

```{multCode}

``{r, eval = F}

#Things start to get more complicated with Base R

split(penguins$body_mass_g, penguins$species) |> 
    lapply(function(x) c(min(x, na.rm = TRUE), max(x, na.rm = TRUE))) |> 
    do.call(rbind, args = _ ) |> 
  as.data.frame()


``

####

``{r, eval = F}
penguins |> 
  group_by(species) |>  # subsequent functions are perform "by group"
  summarise(min=min(body_mass_g, na.rm=TRUE), 
            max=max(body_mass_g, na.rm=TRUE))
``

```

Now we know a little more about our data, the max weight of our Gentoo penguins is much larger than the other two species. In fact, the minimum weight of a Gentoo penguin is not far off the max weight of the other two species. 


### Distinct

We can also look for typos by asking R to produce all of the distinct values in a variable. This is more useful for categorical data, where we expect there to be only a few distinct categories

```{multCode}

``{r, eval = F}


unique(penquins$sex) # only works on vectord

``

####

``{r, eval = F}
penguins |>  
  distinct(sex)
``

```

Here if someone had mistyped e.g. 'FMALE' it would be obvious. We could do the same thing (and probably should have before we changed the names) for species. 

### Missing values: NA

There are multiple ways to check for missing values in our data

```{r, eval = F}
# Get a sum of how many observations are missing in our dataframe
penguins |> 
  is.na() |> 
  sum()

```

But this doesn't tell us where these are, fortunately the function `summary` does this easily

## `Summary`

```{r, eval = F}
# produce a summary of our data
summary(penguins)
#__________________________----
```

This provides a quick breakdown of the max and min for all numeric variables, as well as a list of how many missing observations there are for each one. As we can see there appear to be two missing observations for measurements in body mass, bill lengths, flipper lengths and several more for blood measures. We don't know for sure without inspecting our data further, *but* it is likely that the two birds are missing multiple measurements, and that several more were measured but didn't have their blood drawn. 

We will leave the NA's alone for now, but it's useful to know how many we have. 

We've now got a clean & tidy dataset, with a handful of first insights into the data. 


```{r, echo = F}
save(penguins, file = here("book", "files", "chapter4.RData"))
```


```{r, include = FALSE}
load(here::here("book", "files", "chapter4.RData"))
```


## More summary tools

Very often we want to make calculations aobut groups of observations, such as the mean or median. We are often interested in comparing responses among groups. For example, we previously found the number of distinct penguins in our entire dataset.

```{block, type = "try"}
Add these new lines of code to your script as you try them.
Comment out # and add short descriptions of what you are achieving with them

```

```{multCode}

``{r, eval = F}

unique(penguins$individual_id) |> 
  length()
``

####

``{r}
penguins |> 
  summarise(n_distinct(individual_id))
``

```

Now consider when the groups are subsets of observations, as when we find out the number of penguins in each species and sex.

```{multCode}

``{r, eval = FALSE}

# note aggregate doesn't have functionality to deal with missing data
aggregate(individual_id ~ species + sex, 
          data = penguins, 
          FUN = function(x) length(unique(x)))


``

####

``{r, eval = F}
penguins |> 
  group_by(species, sex) |> 
  summarise(n_distinct(individual_id))

``

```

As we progress, not only are we learning how to use our data wrangling tools. We are also gaining insights into our data. 

**Question** How many female Adelie penguins are in our dataset? 

`r fitb("65")`

<br>

**Question** How many Gentoo penguins **did not** have their sex recorded?

`r fitb("5")`

<br>

We are using summarise and group_by a lot! They are very powerful functions:

* `group_by` adds *grouping* information into a data object, so that subsequent calculations happen on a *group-specific* basis. 

* `summarise` is a data aggregation function thart calculates summaries of one or more variables, and it will do this separately for any groups defined by `group_by`

### summarise()

`summarise()` has a whole list of useful functions for producing *descriptive* statistics

```{r, eval = TRUE, echo = FALSE, warning = FALSE, message = FALSE}


verb <- c( "mean(), median()",
           "sd(), IQR()",
           "min(), max(), quantile()",
           "first(), last(), nth()",
           "n(), n_distinct()")

action <- c("Center data",
            "Spread of data",
            "Range of data",
            "Position",
            "Count")

box <- tibble(verb, action)

box

```

* `min` and `max` to calculate minimum and maximum values of a numeric vector

* `mean` and `median` to calculate averages of a numeric vector

* `sd` and `var` calculate standard deviation and variance of a numeric vector

Using `summarise` we can calculate the mean flipper and bill lengths of our penguins:

```{r, eval  = F}
penguins |> 
  summarise(
    mean_flipper_length = mean(flipper_length_mm, na.rm=TRUE),
     mean_culmen_length = mean(culmen_length_mm, na.rm=TRUE))

```

```{block, type = "info"}
Note - we provide informative names for ourselves on the left side of the `=` 

When performing calculations in summarise it is important to set `na.rm = TRUE`, this removes missing values from the calculation
```


```{block, type = "try"}

What happens when you try to produce calculations that include `NA`? 
e.g `NA` + 4 or `NA` * 5

```

We can use several functions in `summarise`. Which means we can string several calculations together in a single step, and generate more insights into our data.

```{r, eval  = F}
penguins |> 
  summarise(n=n(), # number of rows of data
            num_penguins = n_distinct(individual_id), # number of unique individuals
            mean_flipper_length = mean(flipper_length_mm, na.rm=TRUE), # mean flipper length
            prop_female = sum(sex == "FEMALE", na.rm=TRUE) / n()) # proportion of observations that are coded as female
            

```


```{solution}

There are 190 unique IDs and 344 total observations so it would appear that there are roughly twice as many observations as unique individuals. The sex ratio is roughly even (48% female) and the average flipper length is 201 mm.

```


#### Summarize `across` columns


`across` has two arguments, `.cols` and `.fns`. 

* The `.cols` argument lets you select the columns you wish to apply functions to

* The `.fns` argument applies the required function to all of the selected columns. 


```{r, eval  = F}
# Across ----
# The mean of ALL numeric columns in the data, where(is.numeric == TRUE) hunts for numeric columns

penguins |> 
  summarise(across(.cols = where(is.numeric), 
                   .fns = ~ mean(., na.rm=TRUE)))

```

The above example calculates the means of any & all numeric variables in the dataset. 

The below example is a slightly complicated way of running the n_distinct for summarise. The `.cols()` looks for any column that contains the word "penguin" and then runs the `n_distinct()`command on these

```{r, eval  = F}
# number of distinct penguins, as only one column contains the word penguin
# the argument contains looks for columns that match a character expression

penguins |> 
  summarise(across(.cols = contains("individual"), 
                   .fns = ~n_distinct(.)))

```

### group_by revisited

The `group_by` function provides the ability to separate our summary functions according to any subgroups we wish to make. The real magic happens when we pair this with `summarise` and `mutate`.

In this example, by grouping on the individual penguin ids, then summarising by n - we can see how many times each penguin was monitored in the course of this study. 

```{r, eval  = F}
penguin_stats <- penguins |> 
  group_by(individual_id) |> 
  summarise(num=n())
```


```{block, type = "info"}
Remember the actions of `group_by` are "invisible". Subsequent functions are applied in a "grouped by" manner - but the dataframe itself looks unchanged.

```

#### More than one grouping variable

What if we need to calculate by more than one variable at a time? 
No problem we can submit several arguments:

```{r, eval  = F}
penguins_grouped <- penguins |> 
  group_by(sex, species)

```

 We can then calculate the mean flipper length of penguins in each of the six combinations

```{r, eval  = F}
penguins_grouped |> 
summarise(mean_flipper = mean(flipper_length_mm, na.rm=TRUE))
```

Now the first row of our summary table shows us the mean flipper length (in mm) for female Adelie penguins. There are eight rows in total, six unique combinations and two rows where the sex of the penguins was not recorded(`NA`)

#### using group_by with mutate

So far we have only used `group_by` with the `summarise` function, but this doesn't always have to be the case. 
When `mutate` is used with `group_by`, the calculations occur by 'group'. Here's an example:

```{r, eval  = F}
# Using mutate and group_by ----
centered_penguins <- penguins |> 
  group_by(sex, species) |> 
  mutate(flipper_centered = flipper_length_mm-mean(flipper_length_mm, na.rm=TRUE))

centered_penguins |> 
  select(flipper_centered)
# Each row now returns a value for EACH penguin of how much greater/lesser than the group average (sex and species) its flipper is. 

```

Here we are calculating a **group centered mean**, this new variable contains the *difference* between each observation and the mean of whichever group that observation is in. 

#### remove group_by

On occasion we may need to remove the grouping information from a dataset. This is often required when we string pipes together, when we need to work using a grouping structure, then revert back to the whole dataset again

Look at our grouped dataframe, and we can see the information on groups is at the top of the data:

```
# A tibble: 344 x 10
# Groups:   sex, species [8]
   species island culmen_length_mm culmen_depth_mm flipper_length_~ body_mass_g
   <chr>   <chr>           <dbl>         <dbl>            <dbl>       <dbl>
 1 Adelie  Torge~           39.1          18.7              181        3750
 2 Adelie  Torge~           39.5          17.4              186        3800
 3 Adelie  Torge~           40.3          18                195        3250
 ```


```{r, eval  = F}
# Run this command will remove the groups - but this is only saved if assigned BACK to an object

centered_penguins <- centered_penguins |> 
  ungroup()

centered_penguins

```

Look at this output - you can see the information on groups has now been removed from the data. 

## Working with character strings

Datasets often contain words, and we call these words "(character) strings". 

Often these aren't quite how we want them to be, but we can manipulate these as much as we like. Functions in the package `stringr`, are fantastic. And the number of different types of manipulations are endless!

```{r, eval  = F}

# Stringr ----

str_replace_all(names(penguins), c("e"= "E"))
# replace all character "e" with "E"
```


### More stringr

```{r, eval  = F}
penguins  |>  
  mutate(species=str_to_upper(species))
# Capitalise all letters

```

```{r, eval  = F}
penguins |> 
  mutate(species=str_remove_all(species, "e"))
# remove every character "e" from selected variables
```

We can also trim leading or trailing empty spaces with `str_trim`. These are often problematic and difficult to spot e.g.

```{r, eval  = F}
df2 <- tibble(label=c("penguin", " penguin", "penguin ")) 
df2 # make a test dataframe
```

We can easily imagine a scenario where data is manually input, and trailing or leading spaces are left in. These are difficult to spot by eye - but problematic because as far as R is concerned these are different values. We can use the function `distinct` to return the names of all the different levels it can find in this dataframe.

```{r, eval  = F}
df2 |> 
  distinct()
```

If we pipe the data throught the `str_trim` function to remove any gaps, then pipe this on to `distinct` again - by removing the whitespace, R now recognises just one level to this data. 

```{r, eval  = F}
df2 |> 
  mutate(label=str_trim(label, side="both")) |> 
  distinct()

```

A quick example of how to extract partial strings according to a pattern is to use `str_detect`. Combined with `filter` it is possible to subset a dataframe by searching for all the strings that match provided information, such as all the penguin IDs that start with "N1"

```{r, eval  = F}
penguins |> 
  filter(str_detect(individual_id, "N1"))

```

### separate

Sometimes a string might contain two pieces of information in one. This does not confirm to our tidy data principles. But we can easily separate the information with `separate()` from the `tidyr` package.

First we produce some made-up data

```{r}
df <- tibble(label=c("a-1", "a-2", "a-3")) 
#make a one column tibble
df
```

```{r}
df |> 
  separate(label, # name of variable
           c("treatment", "replicate"), # new column names
           sep="-") # the character to mark where the separation occurs

```

We started with one variable called `label` and then split it into two variables, `treatment` and `replicate`, with the split made where `-` occurs. 
The opposite of this function is `unite()`

## Working with dates

Working with dates can be tricky, treating date as strictly numeric is problematic, it won't account for number of days in months or number of months in a year. 

Additionally there's a lot of different ways to write the same date:

* 13-10-2019

* 10-13-2019

* 13-10-19

* 13th Oct 2019

* 2019-10-13

This variability makes it difficult to tell our software how to read the information, luckily we can use the functions in the `lubridate` package. 


```{block, type = "warning"}
If you get a warning that some dates could not be parsed, then you might find the date has been inconsistently entered into the dataset.

Pay attention to warning and error messages
```

Depending on how we interpret the date ordering in a file, we can use `ymd()`, `ydm()`, `mdy()`, `dmy()` 

* **Question** What is the appropriate function from the above to use on the `date_egg` variable?


`r longmcq(c("ymd()", "ydm()", "mdy()", answer="dmy()"))`


```{solution}


``{r, eval = F, warning = F, message = F}

penguins <- penguins |>
  mutate(date_egg_proper = lubridate::dmy(date_egg))

``

```


Here we use the `mutate` function from `dplyr` to create a *new variable* called `date_egg_proper` based on the output of converting the characters in `date_egg` to date format. The original variable is left intact, if we had specified the "new" variable was also called `date_egg` then it would have overwritten the original variable. 



Once we have established our date data, we are able to perform calculations. Such as the date range across which our data was collected.  

```{r, echo = F}
penguins <- penguins |>
  mutate(date_egg_proper = lubridate::dmy(date_egg))
```


```{r, eval = F}
penguins |> 
  summarise(min_date=min(date_egg_proper),
            max_date=max(date_egg_proper))
```

#### Calculations with dates

How many times was each penguin measured, and across what total time period?

```{r, eval = F}
penguins |> 
  group_by(individual_id) |> 
  summarise(first_observation=min(date_egg_proper), 
            last_observation=max(date_egg_proper), 
            study_duration = last_observation-first_observation, 
            n=n())
```

Cool we can also convert intervals such as days into weeks, months or years with `dweeks(1)`, `dmonths(1)`, `dyears(1)`.

As with all cool functions, you should check out the RStudio [cheat sheet](https://www.rstudio.com/resources/cheatsheets/) for more information. Date type data is common in datasets, and learning to work with it is a useful skill. 


```{r, eval = F}
penguins |> 
  group_by(individual_id) |> 
  summarise(first_observation=min(date_egg_proper), 
            last_observation=max(date_egg_proper), 
            study_duration_years = (last_observation-first_observation)/lubridate::dyears(1), 
            n=n()) |> 
    arrange(desc(study_duration_years))

```


Or extract the year from the date - let's do this now and update our dataframe

```{r}

penguins <- penguins |> 
  mutate(year = as.integer(lubridate::year(date_egg_proper)))

```


## Factors

In R, factors are a class of data that allow for **ordered categories** with a fixed set of acceptable values. 

Typically, you would convert a column from character or numeric class to a factor if you want to set an intrinsic order to the values (‚Äúlevels‚Äù) so they can be displayed non-alphabetically in plots and tables, or for use in linear model analyses (more on this later). 

Another common use of factors is to standardise the legends of plots so they do not fluctuate if certain values are temporarily absent from the data.

```{r, eval = T, warning = F, message = F}
penguins <- penguins |> 
  mutate(flipper_range = case_when(flipper_length_mm <= 190 ~ "small",
                                   flipper_length_mm >190 & flipper_length_mm < 213 ~ "medium",
                                   flipper_length_mm >= 213 ~ "large"))
```

If we make a barplot, the order of the values on the x axis will typically be in alphabetical order for any character data

```{r, eval = T, warning = F, message = F}
penguins |> 
  ggplot(aes(x = flipper_range))+
  geom_bar()

```

To convert a character or numeric column to class factor, you can use any function from the `forcats` package. They will convert to class factor and then also perform or allow certain ordering of the levels - for example using `forcats::fct_relevel()` lets you manually specify the level order. 

The function `as_factor()` simply converts the class without any further capabilities.

The `base R` function `factor()` converts a column to factor and allows you to manually specify the order of the levels, as a character vector to its `levels =` argument.

Below we use `mutate()` and `fct_relevel()` to convert the column flipper_range from class character to class factor. 

```{multCode}

``{r, eval = F, warning=FALSE, message = F}

penguins$flipper_range <- factor(penguins$flipper_range)

``

####

``{r, eval = T, warning=FALSE, message = F}
penguins <- penguins |> 
  mutate(flipper_range = fct_relevel(flipper_range))

``

```


```{r}
levels(penguins$flipper_range)
```


```{multCode}

``{r}

penguins$flipper_range <- factor(penguins$flipper_range,
                                  levels = c("small", "medium", "large"))

``

####

``{r}
# Correct the code in your script with this version
penguins <- penguins |> 
  mutate(flipper_range = fct_relevel(flipper_range, "small", "medium", "large"))

``

```

Now when we call a plot, we can see that the x axis categories match the intrinsic order we have specified with our factor levels. 

```{r, eval = T, warning = F, message = F}
penguins |> 
  ggplot(aes(x = flipper_range))+
  geom_bar()

```

```{block, type = "info"}

Factors will also be important when we build linear models a bit later. The reference or intercept for a categorical predictor variable when it is read as a `<chr>` is set by R as the first one when ordered alphabetically. This may not always be the most appropriate choice, and by changing this to an ordered `<fct>` we can manually set the intercept.

```



## Finished

* Make sure you have **saved your script üíæ**  and given it the filename "01_import_penguins_data.R" in the ["scripts" folder](#activity-1-organising-our-workspace).

* You have been playing with a lot of dplyr functions, think - what functions do I actually need to make sure I have a tidy and clean dataset with appropriate column names and formatted data?

* We want : snake_case names, shorter isotope names, simpler species values and properly formatted date data with a new column for year.

`r hide("Check your script")`

```{r, eval = F, echo = T, fig.height=6, fig.width=6, out.width = "60%"}
#___________________________----
# SET UP ----
## An analysis of the bill dimensions of male and female Adelie, Gentoo and Chinstrap penguins ----

### Data first published in  Gorman, KB, TD Williams, and WR Fraser. 2014. ‚ÄúEcological Sexual Dimorphism and Environmental Variability Within a Community of Antarctic Penguins (Genus Pygoscelis).‚Äù PLos One 9 (3): e90081. https://doi.org/10.1371/journal.pone.0090081. ----
#__________________________----

# PACKAGES ----
library(tidyverse) # tidy data packages
library(janitor) # cleans variable names
#__________________________----
# IMPORT DATA ----
penguins_raw <- read_csv ("data/penguins_raw.csv")

attributes(penguins_raw) # reads as tibble

head(penguins_raw) # check the data has loaded, prints first 10 rows of dataframe
#__________________________----
# CLEAN DATA ----

# clean all variable names to snake_case using the clean_names function from the janitor package
# note we are using assign <- to overwrite the old version of penguins with a version that has updated names
# this changes the data in our R workspace but NOT the original csv file

penguins_clean <- janitor::clean_names(penguins_raw) # clean the column names

colnames(penguins_clean) # quickly check the new variable names

# shorten the variable names for N and C isotope blood samples

penguins <- rename(penguins_clean,
         "delta_15n"="delta_15_n_o_oo",  # use rename from the dplyr package
         "delta_13c"="delta_13_c_o_oo")

# use mutate and case_when for a statement that conditionally changes the names of the values in a variable
penguins <- penguins |> 
  mutate(species = case_when(species == "Adelie Penguin (Pygoscelis adeliae)" ~ "Adelie",
                             species == "Gentoo penguin (Pygoscelis papua)" ~ "Gentoo",
                             species == "Chinstrap penguin (Pygoscelis antarctica)" ~ "Chinstrap"))

# use lubridate to format date and extract the year
penguins <- penguins |>
  mutate(date_egg_proper = lubridate::dmy(date_egg))

penguins <- penguins |> 
  mutate(year = as.integer(lubridate::year(date_egg_proper)))

# Export tidy dataframe for use in future sessions

saveRDS(penguins, file = "outputs/2024_11_01_penguin_clean.RDS")

```

`r unhide()`


* Some parts of our script are *redundant* for the purposes of generating a clean dataframe, we need the `penguins` data in a tidy/rectangular format, checked for missing values, duplicated data and with clean column names. 

* If we have that we can generate a .RDS file to save this dataframe for use in data insights scripts

```{r, eval = F}

saveRDS(penguins, file = "outputs/2024_11_01_penguin_clean.RDS")

```



* Does your workspace look like the below? 

```{r, eval=TRUE, echo=FALSE, out.width="100%",  fig.cap="My neat project layout"}
knitr::include_graphics("images/project_penguin.png")
```

```{r, eval=TRUE, echo=FALSE, out.width="100%",  fig.cap="My scripts and file subdirectory"}
knitr::include_graphics("images/r_script.png")
```

## Activity: Test yourself


**Question 1.** In order to subset a data by **rows** I should use the function `r mcq(c("select()", answer = "filter()", "group_by()"))`

**Question 2.** In order to subset a data by **columns** I should use the function `r mcq(c(answer = "select()", "filter()", "group_by()"))`

**Question 3.** In order to make a new column I should use the function `r mcq(c("group_by()", "select()", answer = "mutate()", "arrange()")) `

**Question 4.** Which operator should I use to send the output from line of code into the next line? `r fitb("|>")`

**Question 5.** What will be the outcome of the following line of code?

```{r, eval = F}
penguins |> 
  filter(species == "Adelie")

```


`r mcq(c("The penguins dataframe object is reduced to include only Adelie penguins from now on", answer = "A new filtered dataframe of only Adelie penguins will be printed into the console"))`


`r hide("Explain this answer")`

Unless the output of a series of functions is "assigned" to an object using `<-` it will not be saved, the results will be immediately printed. This code would have to be modified to the below in order to create a new filtered object `penguins_filtered`

```{r, eval = F}
penguins_filtered <- penguins |> 
  filter(species == "Adelie")

```

`r unhide()`

<br>


**Question 6.** What is the main point of a data "pipe"?

`r mcq(c("The code runs faster", answer = "The code is easier to read"))`


**Question 7.** The naming convention outputted by the function `janitor::clean_names() is 
`r mcq(c(answer = "snake_case", "camelCase", "SCREAMING_SNAKE_CASE", "kebab-case"))`


**Question 8.** Which package provides useful functions for manipulating character strings? 

`r mcq(c(answer = "stringr", "ggplot2", "lubridate", "forcats"))`

**Question 9.** Which package provides useful functions for manipulating dates? 

`r mcq(c("stringr", "ggplot2", answer = "lubridate", "forcats"))`


**Question 10.** If we do not specify a character variable as a factor, then ordering will default to what?

`r mcq(c("numerical", answer = "alphabetical", "order in the dataframe"))`

```{r, echo = F}
save(penguins, file = here("book", "files", "chapter5.RData"))
```

